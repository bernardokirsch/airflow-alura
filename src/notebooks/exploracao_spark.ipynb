{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark==3.3.1 in /home/kirsch/airflowalura/venv/lib/python3.10/site-packages (3.3.1)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in /home/kirsch/airflowalura/venv/lib/python3.10/site-packages (from pyspark==3.3.1) (0.10.9.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark==3.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/05 16:52:49 WARN Utils: Your hostname, kirsch-Virtual-Machine resolves to a loopback address: 127.0.1.1; using 172.28.82.115 instead (on interface eth0)\n",
      "23/05/05 16:52:49 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/05 16:52:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName('twitter_transformation')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.json('../../datalake/twitter_datascience')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------+------------+\n",
      "|                data|            includes|              meta|extract_date|\n",
      "+--------------------+--------------------+------------------+------------+\n",
      "|[{5, 66, 2023-04-...|{[{2023-04-29T21:...|{1234567890abcdef}|  2023-04-29|\n",
      "|[{19, 21, 2023-04...|{[{2023-04-29T13:...|{1234567890abcdef}|  2023-04-29|\n",
      "|[{45, 74, 2023-04...|{[{2023-04-29T12:...|{1234567890abcdef}|  2023-04-29|\n",
      "|[{39, 87, 2023-04...|{[{2023-04-29T11:...|              null|  2023-04-29|\n",
      "|[{92, 41, 2023-05...|{[{2023-05-03T06:...|{1234567890abcdef}|  2023-05-03|\n",
      "|[{18, 47, 2023-05...|{[{2023-05-03T20:...|{1234567890abcdef}|  2023-05-03|\n",
      "|[{54, 80, 2023-05...|{[{2023-05-03T04:...|              null|  2023-05-03|\n",
      "|[{25, 16, 2023-04...|{[{2023-04-28T18:...|{1234567890abcdef}|  2023-04-28|\n",
      "|[{9, 17, 2023-04-...|{[{2023-04-28T23:...|              null|  2023-04-28|\n",
      "|[{20, 100, 2023-0...|{[{2023-05-01T10:...|{1234567890abcdef}|  2023-05-01|\n",
      "|[{63, 1, 2023-05-...|{[{2023-05-01T16:...|              null|  2023-05-01|\n",
      "|[{35, 88, 2023-05...|{[{2023-05-04T20:...|{1234567890abcdef}|  2023-05-04|\n",
      "|[{34, 2, 2023-05-...|{[{2023-05-04T04:...|              null|  2023-05-04|\n",
      "|[{82, 79, 2023-04...|{[{2023-04-30T01:...|              null|  2023-04-30|\n",
      "|[{64, 60, 2023-05...|{[{2023-05-02T03:...|              null|  2023-05-02|\n",
      "+--------------------+--------------------+------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- data: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- author_id: string (nullable = true)\n",
      " |    |    |-- conversation_id: string (nullable = true)\n",
      " |    |    |-- created_at: string (nullable = true)\n",
      " |    |    |-- edit_history_tweet_ids: array (nullable = true)\n",
      " |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- in_reply_to_user_id: string (nullable = true)\n",
      " |    |    |-- lang: string (nullable = true)\n",
      " |    |    |-- public_metrics: struct (nullable = true)\n",
      " |    |    |    |-- like_count: long (nullable = true)\n",
      " |    |    |    |-- quote_count: long (nullable = true)\n",
      " |    |    |    |-- reply_count: long (nullable = true)\n",
      " |    |    |    |-- retweet_count: long (nullable = true)\n",
      " |    |    |-- text: string (nullable = true)\n",
      " |-- includes: struct (nullable = true)\n",
      " |    |-- users: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- created_at: string (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- username: string (nullable = true)\n",
      " |-- meta: struct (nullable = true)\n",
      " |    |-- next_token: string (nullable = true)\n",
      " |-- extract_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- col: struct (nullable = true)\n",
      " |    |-- author_id: string (nullable = true)\n",
      " |    |-- conversation_id: string (nullable = true)\n",
      " |    |-- created_at: string (nullable = true)\n",
      " |    |-- edit_history_tweet_ids: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- in_reply_to_user_id: string (nullable = true)\n",
      " |    |-- lang: string (nullable = true)\n",
      " |    |-- public_metrics: struct (nullable = true)\n",
      " |    |    |-- like_count: long (nullable = true)\n",
      " |    |    |-- quote_count: long (nullable = true)\n",
      " |    |    |-- reply_count: long (nullable = true)\n",
      " |    |    |-- retweet_count: long (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(f.explode('data')).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 col|\n",
      "+--------------------+\n",
      "|{5, 66, 2023-04-2...|\n",
      "|{22, 45, 2023-04-...|\n",
      "|{29, 16, 2023-04-...|\n",
      "|{90, 52, 2023-04-...|\n",
      "|{97, 0, 2023-04-2...|\n",
      "|{95, 38, 2023-04-...|\n",
      "|{64, 27, 2023-04-...|\n",
      "|{91, 87, 2023-04-...|\n",
      "|{8, 51, 2023-04-2...|\n",
      "|{62, 13, 2023-04-...|\n",
      "|{19, 21, 2023-04-...|\n",
      "|{12, 86, 2023-04-...|\n",
      "|{12, 0, 2023-04-2...|\n",
      "|{29, 20, 2023-04-...|\n",
      "|{7, 96, 2023-04-2...|\n",
      "|{49, 95, 2023-04-...|\n",
      "|{32, 42, 2023-04-...|\n",
      "|{96, 67, 2023-04-...|\n",
      "|{87, 98, 2023-04-...|\n",
      "|{79, 90, 2023-04-...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(f.explode('data')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author_id: string (nullable = true)\n",
      " |-- conversation_id: string (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- like_count: long (nullable = true)\n",
      " |-- quote_count: long (nullable = true)\n",
      " |-- reply_count: long (nullable = true)\n",
      " |-- retweet_count: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(f.explode('data').alias('tweets'))\\\n",
    "  .select('tweets.author_id', 'tweets.conversation_id',\n",
    "          'tweets.created_at', 'tweets.id', \n",
    "          'tweets.public_metrics.*', 'tweets.text').printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+--------------------+---+----------+-----------+-----------+-------------+--------------------+\n",
      "|author_id|conversation_id|          created_at| id|like_count|quote_count|reply_count|retweet_count|                text|\n",
      "+---------+---------------+--------------------+---+----------+-----------+-----------+-------------+--------------------+\n",
      "|        5|             66|2023-04-29T01:57:41Z| 46|        65|          6|         93|           53|Um terceiro tweet...|\n",
      "|       22|             45|2023-04-29T23:55:35Z| 29|         6|          0|         24|           87|Este é um tweet f...|\n",
      "|       29|             16|2023-04-29T05:37:04Z| 42|         8|         45|         74|           83|Tweet fictício ge...|\n",
      "|       90|             52|2023-04-29T17:32:10Z| 49|        50|         93|         51|           24|Tweet fictício ge...|\n",
      "|       97|              0|2023-04-29T21:32:27Z| 26|        68|         27|         31|           86|Tweet fictício cr...|\n",
      "+---------+---------------+--------------------+---+----------+-----------+-----------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweet_df = df.select(f.explode('data').alias('tweets'))\\\n",
    "             .select('tweets.author_id', 'tweets.conversation_id',\n",
    "                     'tweets.created_at', 'tweets.id', \n",
    "                     'tweets.public_metrics.*', 'tweets.text')\n",
    "\n",
    "tweet_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+------+--------+\n",
      "|          created_at| id|  name|username|\n",
      "+--------------------+---+------+--------+\n",
      "|2023-04-29T21:13:11Z| 16|User 1|   user1|\n",
      "|2023-04-29T11:21:08Z| 80|User 2|   user2|\n",
      "|2023-04-29T18:28:47Z| 99|User 3|   user3|\n",
      "|2023-04-29T10:06:15Z| 51|User 4|   user4|\n",
      "|2023-04-29T00:27:26Z| 55|User 5|   user5|\n",
      "+--------------------+---+------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df = df.select(f.explode('includes.users').alias('users'))\\\n",
    "             .select('users.created_at', 'users.id',\n",
    "                     'users.name', 'users.username')\n",
    "\n",
    "user_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tweet_df.coalesce(1).write.mode('overwrite').json('output/tweet')\n",
    "user_df.coalesce(1).write.mode('overwrite').json('output/user')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
